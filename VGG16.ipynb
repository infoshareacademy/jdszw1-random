{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS_FILE = \"/home/katarzyna/Desktop/datasets/dresses/train/labels.txt\"\n",
    "VAL_LABELS_FILE = \"/home/katarzyna/Desktop/datasets/dresses/val/labels.txt\"\n",
    "TEST_LABELS_FILE = \"/home/katarzyna/Desktop/datasets/dresses/test/labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/katarzyna/Desktop/datasets/dresses/train/labels.txt', delimiter=' ',\n",
    "                 names=[\"path\", 'beige', 'black', 'blue', 'brown', 'gray', 'green', 'multicolor',\n",
    "                        'orange', 'pink', 'red', 'violet', 'white', 'yellow', 'transaprent'], dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(filename, number=None):\n",
    "    # załadowanie pliku txt do ramki pandas\n",
    "    df = pd.read_csv('/home/katarzyna/Desktop/datasets/dresses/train/labels.txt', delimiter=' ', names=[\"path\", 'beige', 'black', 'blue', 'brown', 'gray', 'green', 'multicolor', 'orange', 'pink', 'red', 'violet', 'white', 'yellow', 'transaprent'], dtype=\"str\")\n",
    "    # stworzenie generatora\n",
    "    gen = image.ImageDataGenerator()\n",
    "    # folder z danymi, do którego będą doklejane ścieżki z odpowiedniej kolumny\n",
    "    directory = os.path.dirname(filename)\n",
    "    # stworzenie iteratora po danych z zadanymi opcjami\n",
    "    return gen.flow_from_dataframe(df, directory, \"path\", class_mode=\"raw\", y_col=['beige', 'black', 'blue', 'brown', 'gray', 'green', 'multicolor', 'orange', 'pink', 'red', 'violet', 'white', 'yellow', 'transaprent'], target_size=(128, 128), batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dataset(flow):\n",
    "    for img, l in flow:\n",
    "        # wypisz etykietę\n",
    "        print(l[0])\n",
    "        # konwersja obrazu do wyświetlenia\n",
    "        img = img[0].astype(np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        # wyświetl obraz\n",
    "        cv2.imshow(\"image\", img)\n",
    "        # poczekaj na klawisz\n",
    "        cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(gen):\n",
    "    model = VGG16()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks():\n",
    "    callbacks =[]\n",
    "    mc=keras.callbacks.ModelCheckpoint(\"weights1.hdf5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "    callbacks.append(mc)\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train_gen = get_generator(TRAIN_LABELS_FILE)\n",
    "    val_gen = get_generator(VAL_LABELS_FILE)\n",
    "    callbacks = get_callbacks()\n",
    "    # stwórz model\n",
    "    model = create_model(train_gen)\n",
    "    #model.load_weights('weights1.hdf5')\n",
    "    #model.summary()\n",
    "    # trening :)\n",
    "    model.fit_generator(train_gen, epochs=30, steps_per_epoch=train_gen.n // train_gen.batch_size)\n",
    "                        #validation_data = val_gen, validation_steps = val_gen.n // val_gen.batch_size) \n",
    "                        #callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3514 validated image filenames.\n",
      "Found 0 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/katarzyna/.local/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:273: UserWarning: Found 3514 invalid image filename(s) in x_col=\"path\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "369131520/553467096 [===================>..........] - ETA: 23s"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
